> [!info]  
> На собеседованиях по Go часто проверяют понимание конкурентности, потому что горутины и каналы — ключевые особенности языка. Умение объяснить и избегать ошибок вроде data race или deadlock показывает зрелость кандидата и опыт работы с многопоточными системами.

---

## Краткий конспект

- **Data race** — одновременный доступ к переменной из нескольких горутин без синхронизации.
- **Race condition** — ошибка из-за зависимости от порядка исполнения.
- **Deadlock** — горутины заблокированы и не могут продолжить выполнение.
- **Starvation** — одна горутина не получает доступа к ресурсу из-за других.
- **Goroutine Leak** — горутина «зависает» и не завершается.
- Используй [[Тестирование и анализ качества|go test -race]] для выявления гонок.
- [[Тестирование и анализ качества#go vet|go vet]] и [[Профилирование и отладка|pprof]] помогают находить ошибки конкурентности и утечки.

---

## Что такое data race и race condition?

**Data race** возникает, когда:
1. Есть хотя бы две горутины.
2. Они обращаются к одной переменной.
3. Хотя бы одна из них записывает.
4. Нет синхронизации (mutex, канал и т.п.).

**Race condition** — более общий термин, означающий, что результат зависит от порядка выполнения горутин. Не всегда проявляется как ошибка, но может привести к непредсказуемому поведению.

```go
package main

import "fmt"

var counter int

func main() {
	for i := 0; i < 1000; i++ {
		go func() {
			counter++
		}()
	}
	fmt.Println("Done:", counter)
}
```

Запусти так:

```bash
go run -race main.go
```

> [!warning]
> `-race` покажет предупреждение, так как несколько горутин пишут в `counter` без синхронизации.

> [!faq]  
> **Q:** Чем отличается data race от race condition?  
> **A:** Data race — частный случай race condition, когда есть параллельные обращения без синхронизации. Race condition может не вызывать гонки на уровне памяти, но всё ещё приводит к багам.


---

## Другие типичные проблемы

### Deadlock

**Определение:** ситуация, при которой несколько горутин навсегда ожидают друг друга и не могут продолжить.

**Когда проявляется:** при блокирующем чтении/записи в каналы без парной операции.

```go
func main() {
	ch := make(chan int)
	ch <- 1 // deadlock: никто не читает
}
```

> [!faq]  
> **Q:** Как найти и воспроизвести deadlock?  
> **A:** Запустить код и посмотреть, где программа «зависает». Использовать `pprof`, блокирующие трассы и упрощение логики.

---

### Starvation

**Определение:** горутина долго не получает CPU/ресурс, потому что другие забирают его все время.
#### Признаки

- «Подвисшие» запросы при высокой загрузке CPU.
    
- В `pprof` одни и те же горутины активны, остальные простаивают.

```go
var mu sync.Mutex

func lockedLoop() {
	mu.Lock()
	defer mu.Unlock()
	for {
		// бесконечная работа
	}
}
```

#### Как обнаружить

- `go tool pprof profile`
    
- `GODEBUG=schedtrace=1000`
    
- `runtime/trace`

#### Как устранить

- Дробить работу, вставлять `runtime.Gosched()`.
    
- Увеличить `GOMAXPROCS`.
    
- Лимитировать число горутин и время под мьютексом.

#### Родственные явления

`deadlock` — всё стоит; `livelock` — всё крутится; `starvation` — простаивает лишь часть.

---

### Goroutine Leak

**Определение:** горутина была создана, но никогда не завершается.

**Когда проявляется:** забыли закрыть канал, не реализовали отмену по `context`.

```go
func watch(ch <-chan int) {
	for val := range ch {
		fmt.Println(val)
	}
}

func main() {
	ch := make(chan int)
	go watch(ch)
	// ch никогда не закрывается — утечка
}
```

> [!faq]  
> **Q:** Как избежать утечки горутин?  
> **A:** Использовать `context.Context`, закрывать каналы, избегать бесконечных ожиданий без выхода.

---

### Livelock

**Определение:** горутины активно занимают CPU, постоянно реагируя друг на друга, но не двигаются к цели — «вежливо уступают», поэтому система не прогрессирует.
#### Признаки

- Высокая загрузка CPU при нулевом полезном результате.
    
- В `runtime/trace` видно многократные блокировки/разблокировки, но почти нет пользовательского кода.
    
- Метрики задержек растут, несмотря на «крутящийся» сервис.
    

#### Причины

|Причина|Суть|
|---|---|
|**Избыточная уступчивость**|Горутины часто вызывают `runtime.Gosched()` или `time.Sleep(...)`, пытаясь «дать дорогу» другому.|
|**Переговоры по каналу**|Две (или больше) горутин непрерывно отправляют/читают друг другу сообщения, меняя намерение на каждое действие.|
|**Пере‑Retry logic**|Агрессивные ретраи без экспоненциальной задержки — конкуренты постоянно сообщают «занято».|

#### Мини‑пример

```go
// Две горутины, по очереди уступающие канал
func courteous(id int, c chan struct{}) {
	for {
		<-c           // ждём свой ход
		// «Вежливо» уступаем, не делая работы
		c <- struct{}{}
	}
}

func main() {
	ch := make(chan struct{}, 1)
	ch <- struct{}{}          // стартовый токен
	go courteous(1, ch)
	go courteous(2, ch)
	select {}                 // livelock: токен мечется, работа — ноль
}
```

#### Как обнаружить

1. **`runtime/trace` ➜ «View Trace»** — много мелких событий «send/recv» без выполнения.
    
2. **`pprof` CPU** — огромный вклад в каналы / `runtime.chan` / `runtime.selectgo`.
    
3. **Метрики бизнес‑логики** стоят, счётчики системных вызовов растут.
    

---

### Priority Inversion

**Определение:** низкоприоритетная горутина владеет ресурсом (мьютекс, RW‑lock, канал), а более важная (высокоприоритетная) вынуждена ждать, что блокирует систему.
#### Признаки

- Критически важные запросы зависают, пока второстепенные выполняются.
    
- В профиле блокировок (`go tool pprof block`) видно, что «длинный» хэндлер держит мьютекс, а «короткие» VIP‑горутины ждут.
    

#### Причины

| Причина                         | Суть                                                                         |
| ------------------------------- | ---------------------------------------------------------------------------- |
| **Долгие секции под мьютексом** | Логика, I/O или сетевой вызов внутри `mutex.Lock() … Unlock()`.              |
| **Не‑приоритизированный канал** | Один входной буфер для всех: медленные задачи заполняют очередь первыми.     |

#### Мини‑пример

```go
var mu sync.Mutex

// «Низкий» приоритет — имитируем долгую операцию
func slowWorker() {
	mu.Lock()
	time.Sleep(500 * time.Millisecond) // держим ресурс
	mu.Unlock()
}

// «Высокий» приоритет — хотим быстро пройти
func fastTask(done chan struct{}) {
	start := time.Now()
	mu.Lock()               // придётся ждать slowWorker
	mu.Unlock()
	done <- struct{}{}
	fmt.Println("wait:", time.Since(start))
}

func main() {
	done := make(chan struct{})
	go slowWorker()
	go fastTask(done)
	<-done // Priority inversion: fastTask ждёт ~500 ms
}
```

#### Как обнаружить

- **`go test -race`** + ручные метрики задержки критического пути.
    
- **`go tool trace`** — смотрим, кто держит lock дольше всего.
    
- **`pprof –mutex`** — отчёт о горутинах, владеющих мьютексами.
    

> [!summary]  
> **Livelock — все активно, но нет прогресса.  
> Priority inversion — важное ждёт, пока маловажное держит ресурс.**  
> Для обеих проблем в Go помогают: короткие критические секции, back‑off стратегии и глубокий анализ `runtime/trace`.

---
## Инструменты диагностики

- [[Тестирование и анализ качества|go test -race]] — проверка на data race.
- [[Тестирование и анализ качества|go vet]] — статический анализ, выявляет неправильное использование sync.
- [[Профилирование и отладка|pprof]] — визуализация блокировок и горутин.
- `runtime/trace` — трассировка событий исполнения.
- Внешние: `uber-go/goleak`, `deadlock` от `hashicorp`.

> [!example]
> На собеседовании можно упомянуть: «Мы использовали `goleak.VerifyNone(t)` в unit-тестах, чтобы убедиться, что все горутины завершаются».

---

## Как отвечать на собеседовании

Используй технику **STAR** — Situation, Task, Action, Result.

**Пример:**

- **S:** В проде начали появляться странные ошибки с нулевыми значениями.
- **T:** Найти и устранить причину.
- **A:** Запустил `go test -race`, нашёл гонку доступа к кешу в map. Обернул в `sync.Mutex`.
- **R:** Ошибка исчезла, добавили тесты с параллельным доступом.

---

## FAQ по конкурентности в Go

> [!faq]  
> **Q:** Можно ли безопасно писать в `map` из нескольких горутин?  
> **A:** Нет. Используйте `sync.Map` или синхронизацию.  
>  
> **Q:** Почему `select` без `default` может блокировать?  
> **A:** Потому что он ждёт, пока хотя бы один case станет доступным.  
>  
> **Q:** Как отменить горутину?  
> **A:** Через `context.WithCancel` или `context.WithTimeout`.  
>  
> **Q:** Когда использовать `WaitGroup`, а когда `Channel`?  
> **A:** `WaitGroup` — для ожидания завершения, `Channel` — для обмена данными.  
>  
> **Q:** Что будет, если закрыть канал дважды?  
> **A:** Panic.

---

## Полезные ссылки

- [Data Race Detector — go.dev](https://go.dev/doc/articles/race_detector?utm_source=chatgpt.com)
- [Пример deadlock на Stack Overflow](https://stackoverflow.com/questions/54157836/a-simple-example-about-go-channel-with-deadlock-and-why?utm_source=chatgpt.com)
- [Understanding the Go Scheduler — Medium](https://medium.com/@sanilkhurana7/understanding-the-go-scheduler-and-looking-at-how-it-works-e431a6daacf?utm_source=chatgpt.com)
- [Race Conditions and Detection in Go](https://medium.com/@debug-ing/race-conditions-in-go-and-race-detection-07b4a46bf1a9?utm_source=chatgpt.com)
- [Package runtime/pprof — pkg.go.dev](https://pkg.go.dev/runtime/pprof)

---

## ✅ 5 вещей, которые проверить перед live-coding

1. Убедись, что используешь `sync.Mutex`, если изменяешь разделяемые переменные.
2. Проверь, закрываются ли каналы — нет ли утечек.
3. Используй `context.Context` для отмены горутин.
4. Не забудь `go test -race` в конце — лучше один раз увидеть гонку.
5. Опиши порядок действий словами — интервьюер ценит объяснение логики.

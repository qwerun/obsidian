> [!info] Основная идея  
> Observability — это способность понять внутреннее состояние системы по её внешнему поведению. Для разработчиков и SRE это способ быстрее находить, объяснять и устранять проблемы. 

---

## Краткий конспект

- Observability = метрики + логи + трейсы.
- Помогает локализовать и объяснять ошибки, не заходя на сервер.
- Важно для микросервисов и распределённых систем.
- Отличается от Monitoring — даёт не только сигнал, но и контекст.
- Часто реализуется через Prometheus, Grafana, Jaeger, Loki.
- OpenTelemetry — стандарт сбора и экспорта данных.
- Наблюдаемость = быстрее дебажить 500/latency/отказы.
- Часто спрашивают: «Что бы ты посмотрел при ошибке?»

> [!tip] В Go можно внедрить observability на уровне middleware и распространять контекст через `context.Context`.

---

## Три столпа Observability

### Метрики (Metrics)

Собираются числа по времени: latency, ошибки, количество запросов.

**Пример:**  
```bash
http_requests_total{status="500", method="GET"} = 42
```

> [!tip]
> Метрики легко агрегировать и визуализировать, но они дают лишь поверхностную картину.

### Логи (Logs)

Текстовые события с контекстом. Могут быть структурированными (JSON).

**Пример:**
```json
{ "level": "error", "msg": "DB timeout", "trace_id": "abc123" }
```

> [!example]
> При корреляции с трейсом по `trace_id` лог помогает объяснить, **почему** произошла ошибка.

### Трейсы (Traces)

Позволяют увидеть весь путь запроса через микросервисы.

**Пример:** запрос прошёл через `gateway → auth → db`, задержка на `auth`.

> [!tip]
> Если есть только метрики, вы знаете **что** случилось; трейсы покажут **где именно**.

> [!faq]  
> **Q:** Назови пример метрики и как бы ты её использовал.  
> **A:** Например, `p95 latency` — это время, которое не превышают 95% запросов. Если она резко увеличилась, это может означать деградацию производительности. В таком случае трейсы помогают понять, на каком участке пути запроса возникает задержка: например, можно увидеть, что задержка в сервисе `auth` выросла до 1.2 сек, в то время как остальные обрабатываются быстро.  
>  
> **Q:** Как лог и trace могут помочь найти корень проблемы?  
> **A:** Лог показывает конкретные ошибки или неожиданные состояния (например, timeouts, stack traces). Trace дополняет это картиной того, **где именно в цепочке микросервисов** возникла проблема: сколько времени занял каждый шаг, где были ретраи или сбои. Вместе они дают как симптом (лог), так и контекст (trace) — это ускоряет диагностику и устранение.

---

## Observability vs Monitoring

Monitoring — это реакция на известные сигналы (алерты).  
Observability — это способность понять неизвестное состояние системы.

| Что спрашивают              | Monitoring                | Observability             |
|----------------------------|---------------------------|---------------------------|
| Есть ли алерты?            | ✅                         | Часто через метрики       |
| Можно ли понять **причину**?| ❌ (иногда)               | ✅ (через трейсы/логи)     |
| Диагностика новых ошибок   | Ограничена                | Поддерживается            |
| Пример в Prometheus        | `alert: HighErrorRate`     | `rate(http_errors[5m])` + trace

> [!faq]  
> **Q:** Чем отличается observability от monitoring?  
> **A:** Monitoring — это наблюдение за заранее определёнными метриками и алертами (например, CPU > 90%). Observability — это способность исследовать поведение системы и находить корень проблемы даже при неожиданных сбоях, с помощью логов, трейсов и метрик.  
>  
> **Q:** Какая комбинация сигналов нужна для расследования инцидента?  
> **A:** Используют так называемые **"3 столпа наблюдаемости"**:  
> – **Метрики** (например, скорость ошибок, загрузка);  
> – **Логи** (что произошло и когда);  
> – **Трейсы** (что вызвало цепочку вызовов).  
> Вместе они позволяют локализовать и понять причину сбоя.  
>  
> **Q:** Есть ли алерты в monitoring и observability?  
> **A:** Monitoring всегда предполагает алерты. Observability тоже может содержать алерты, но основное — это диагностика, а не реакция.  
>  
> **Q:** Можно ли понять причину проблемы через monitoring?  
> **A:** Обычно нет: monitoring лишь сообщает, *что* сломалось, но не *почему*. Observability помогает докопаться до причины.  
>  
>  **Q:** Какой пример observability в Prometheus?  
> **A:** В monitoring обычно задают алерт, например:  
> ```yaml
> alert: HighErrorRate  
> expr: rate(http_errors_total[5m]) > 0.05
> ```  
> Это сработает, если ошибок слишком много, но не скажет, *почему*.
>
> В observability подход другой:  
> 1. Анализируют метрику `rate(http_errors_total[5m])` вручную — ищут всплески или отклонения.  
> 2. Затем по времени и лейблам (например, `route="/login"`) ищут соответствующие **логи**.  
> 3. После — запускают **трейсинг** (например, Jaeger или OpenTelemetry), чтобы увидеть, где тормозит или падает запрос внутри микросервисов.
>
> Такой путь — метрика → лог → трейс — типичен для реального расследования инцидента.
 
---

## Ключевые инструменты

### Prometheus  
Сбор и хранение метрик. Поддерживает pull-модель.  
Запросы пишутся на языке PromQL.

```bash
rate(http_requests_total[1m])
```

### Grafana  
Панели и дашборды. Используется с Prometheus, Loki, Tempo.

### Jaeger / Tempo  
Трейсинг: визуализация запроса сквозь микросервисы.

### Loki  
Аналог ELK, но проще и лучше интегрируется с Grafana.

### OpenTelemetry  
Стандарт сбора метрик, логов, трейсов. Есть SDK для Go, Java, Python и т.д.

> [!faq]  
> **Q:** Что делает Prometheus?  
> **A:** Систему мониторинга, которая собирает метрики по pull-модели. Используется язык запросов PromQL, например:  
> ```bash
> rate(http_requests_total[1m])
> ```  
> В Go можно экспортировать метрики через `promhttp.Handler()` из пакета `prometheus`.
>
> **Q:** Для чего нужна Grafana?  
> **A:** Для создания дашбордов и визуализации метрик из Prometheus, логов из Loki и трейсов из Tempo.
>
> **Q:** Чем отличаются Jaeger и Tempo?  
> **A:** Оба инструмента — для распределённого трейсинга. Jaeger — старее, Tempo проще масштабируется и лучше дружит с Grafana.
>
> **Q:** Что такое Loki?  
> **A:** Лёгкий сборщик логов, похож на Elasticsearch, но заточен под Kubernetes и работает с Grafana без лишней настройки.
>
> **Q:** Зачем нужен OpenTelemetry?  
> **A:** Это единый стандарт для сбора метрик, логов и трейсов. Поддерживает разные языки, включая Go. Позволяет стандартизировать observability во всех сервисах.
>
> **Q:** А какие инструменты observability ты настраивал сам?  
> **A:** Prometheus и Grafana для метрик, Loki для логов, Jaeger и OpenTelemetry SDK для трейсинга в Go. Настраивал экспорт метрик и трейсов, добавлял middleware с `otelhttp`.
>
> **Q:** Какую метрику ты бы завёл в Prometheus для API latency?  
> **A:** Гистограмму или summary, например:  
> ```go
> prometheus.NewHistogramVec(prometheus.HistogramOpts{
>     Name: "http_request_duration_seconds",
>     Buckets: prometheus.DefBuckets,
> }, []string{"path", "method", "status"})
> ```  
> Это позволит отслеживать p95/p99 и реагировать на аномалии.
>
> **Q:** Как подключить OpenTelemetry в Go?  
> **A:** Через `go.opentelemetry.io/otel`, используя `otelhttp.NewHandler` и экспортёр, например `otlpgrpc`. Важно инициализировать tracer и настроить ресурс с именем сервиса.

---

## Типовые вопросы на собеседовании

> [!faq]  
> **Q:** Чем отличаются логи, трейсы и метрики?  
> **A:** Логи — это текстовые сообщения о событиях, трейсы показывают путь запроса по сервисам, а метрики — агрегированные числовые показатели (latency, RPS).  
>
> **Q:** Как бы ты нашёл источник 500 ошибки без доступа к логам?  
> **A:** Использовал бы трейсы (если есть), метки `status_code=500`, запросил бы воспроизводящий кейс, проверил gRPC ошибки и поведение на соседних инстансах.  
>
> **Q:** Что такое high-cardinality label в Prometheus?  
> **A:** Это метка, принимающая слишком много уникальных значений (например, `user_id`), что может привести к росту нагрузки и OOM.  
>
> **Q:** Как уменьшить overhead от observability-инструментов?  
> **A:** В Go можно включать sampling для трейсов, избегать high-cardinality меток, не логировать в проде DEBUG, и ограничить частоту экспортов метрик.  
>
> **Q:** Что делать, если trace потерялся?  
> **A:** Проверить, настроен ли экспорт (например, OTLP), включён ли sampling, правильно ли прокидываются trace-id между сервисами.  
>
> **Q:** Расскажи кейс, когда трейсы помогли найти узкое место.  
> **A:** В одном проекте трейсы показали, что задержка в ответе шла из-за медленного SQL-запроса на чтение в подзапросе — это не было видно ни по логам, ни по метрикам.  
>
> **Q:** Как отлаживать проблему «долго грузится страница»?  
> **A:** Сначала смотрю метрику latency, потом включаю trace для конкретного запроса, смотрю длительность операций: БД, вызовы между сервисами, рендер.  
>
> **Q:** Использовал ли ты sampling для трейсов?  
> **A:** Да, в Go (через `otel/sdk/trace`) настраивал probabilistic sampling, чтобы не перегружать систему на высоком трафике.


---

> [!warning]
> **Нюансы и подводные камни:**  
> - **Overhead:** при большом объёме трейсов/логов нагрузка на систему может вырасти.  
> - **Sampling:** без выборки — перегруз, с выборкой — не видно редких багов.  
> - **High-cardinality labels:** метки типа `user_id` могут переполнить Prometheus.  
> - **Vendor lock-in:** часть решений завязана на платных SaaS (Datadog, New Relic).

---

> [!faq]  
> **Q:** Я junior. Что точно стоит знать про observability?  
> **A:** Что бывают метрики, логи, трейсы — и они помогают быстро локализовать ошибки.  
>  
> **Q:** Как починить 500 ошибку, если есть только метрики?  
> **A:** Смотри `rate(http_errors_total{status="500"}[5m])`, фильтруй по endpoint'у, ищи всплески и коррелируй с нагрузкой.  
>  
> **Q:** Нужно ли включать трейсы в dev-среде?  
> **A:** Да, это помогает дебажить — но можно ограничить sampling.  
>  
> **Q:** Что выбрать — Jaeger или Zipkin?  
> **A:** Оба подходят, но Jaeger лучше интегрируется с CNCF-стеком.

---

## Полезные ссылки

- [CNCF TAG Observability (GitHub)](https://github.com/cncf/tag-observability?utm_source=chatgpt.com)
- [CrowdStrike — Three Pillars of Observability](https://www.crowdstrike.com/en-us/cybersecurity-101/observability/three-pillars-of-observability/?utm_source=chatgpt.com)
- [RazorOps — Observability Interview Questions](https://razorops.com/blog/top-50-monitoring-and-observality-interview-questions-and-answers/?utm_source=chatgpt.com)
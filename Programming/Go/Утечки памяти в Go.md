## Краткий конспект

- Утечка памяти в Go — это неосвобождённая память, на которую всё ещё ссылается активный объект.
    
- Частые причины: «висящие» горутины, утечки в `sync.Map`, забытые буферы, глобальные слайсы.
    
- `pprof`, `go tool pprof`, `runtime/pprof`, continuous-profiling — ключевые инструменты.
    
- Систематический подход: сравнивать профили, читать flamegraph, смотреть GC-трейсы.
    
- Умение читать `alloc_objects`, `inuse_space` и `cum` — обязательный скилл.
    
- Использование `context.Context` — ключ к отмене лишних горутин.
    
- Не кэшируй бесконтрольно: соблюдай лимиты, TTL, размер map/slice.
    
- Проверяй, закрыт ли канал: `goroutine leak` часто связано с забытым consumer’ом.
    
- Не держи в `sync.Pool` тяжёлые объекты с сильными ссылками.
    
- Cgo: осторожно с освобождением памяти вручную.
    
- Утечки надо ловить в staging/интеграции — не ждать жалоб от продакшена.
    

---

## Что такое утечка памяти в Go

> [!info] **Утечка памяти** — это удержание объектов в памяти дольше, чем требуется, в результате чего они не могут быть собраны сборщиком мусора (GC), даже если не используются по логике приложения.

Go обладает встроенным **сборщиком мусора**, и большинство программистов редко управляют памятью вручную. Однако GC собирает только **недостижимые объекты**. Если переменная или структура остаётся достижимой (например, через замыкание, глобальную ссылку или живую горутину), память не будет освобождена.

Важно отличать **утечку** от **высокой аллокации**. Высокое потребление памяти может быть нормой при активной нагрузке. А утечка — это когда память не освобождается **после завершения работы**, и профиль `heap` показывает накопление `inuse_objects`/`inuse_space`.

---

## Причины утечек памяти

### «Висящие» горутины (`goroutine leak`)

> [!example]
> 
> ```
> func Leaky() {
>     ch := make(chan struct{})
>     go func() {
>         <-ch // никогда не получит значение
>     }()
> }
> ```
> 
> Горутина навсегда останется в `runtime`, удерживая ссылку на `ch` и замыкание.

Подобные утечки часто возникают в pipeline-структурах, где не происходит корректной отмены через `context.Context`.

См. [[Goroutine leak]], [[Контекст отмены в Go]]

---

### Каналы без потребителя

```
ch := make(chan int)
go func() {
    for v := range ch { // ждёт, но никто не пишет
        _ = v
    }
}()
```

> [!warning] Даже если закрыть канал, горутина не завершится, если range не получит EOF (в буферизированном канале). Это приводит к зависанию и удержанию ссылок.

---

### Утечка через слайсы и буферы

```
func ReadLines(file string) [][]byte {
    buf := make([][]byte, 0)
    // читаем строки
    return buf
}
```

Если `buf` ссылается на большой массив, даже при работе с 10KB-строкой может удерживаться 10MB. Всегда копируйте, если нужно уменьшить область памяти:

```
safe := append([]byte(nil), original...) // copy
```

---

### Долгоживущие глобальные ссылки

```
var cache = map[string]*bigStruct{}
```

Если кэш не ограничен по TTL или размеру — он будет расти навсегда.

---

### `sync.Map` и `sync.Pool`

> [!tip] `sync.Pool` не гарантирует удаление: он чистится при GC, но если объект содержит ссылки на большие структуры, это может блокировать освобождение.

```
pool := sync.Pool{New: func() interface{} {
    return make([]byte, 1024*1024) // 1MB
}}
```

---

### Cgo и ручная аллокация

```
ptr := C.malloc(1024)
defer C.free(ptr)
```

Забытая `free` или паника до `defer` — гарантированный `leak`, т.к. GC Go не контролирует C-объекты.

---

## Диагностика: как найти утечку

1. Добавь `net/http/pprof` или `runtime/pprof`
    
2. Снимай профили:
    
    ```
    go tool pprof http://localhost:6060/debug/pprof/heap
    ```
    
3. Сравни профили до/после (`--diff_base`)
    
4. Читай flamegraph: смотри, где скапливается `inuse_objects`
    
5. Анализируй `alloc_space`, `alloc_objects` и stacktrace
    
6. Добавь логирование GC (`GODEBUG=gctrace=1`)
    
7. Используй continuous profiling (Grafana Pyroscope, Datadog, Parca)
    

> [!tip] Снимай профиль при стабильной нагрузке. Не сравнивай idle vs peak.

См. [[Сбор профилей pprof]]

---

## Лучшие практики и защита

- Используй `context.Context` и `select` с `ctx.Done()` внутри каждой горутины
    
- Закрывай каналы, когда producer завершает работу
    
- Ограничивай число горутин через worker pool или `semaphore`
    
- Очищай слайсы: `buf = buf[:0]` или `nil`
    
- Удаляй ключи из `map`/`sync.Map`, если не используешь
    
- Не держи большие объекты в `sync.Pool` дольше, чем нужно
    
- Мониторь heap в staging — проще, чем ловить leak в проде
    

---

> [!faq] **Q:** Как отличить утечку от кэширования?  
> **A:** Сравни пиковое потребление с метриками GC. Утечка — это рост без снижения после GC.
> 
> **Q:** Всегда ли `goroutine` в `runtime.Stack()` — признак утечки?  
> **A:** Нет, нужно анализировать: возможно, она в блокирующем ожидании `select`.
> 
> **Q:** Нужно ли использовать `sync.Pool` для крупных структур?  
> **A:** Не рекомендуется — GC может их не освободить долго, лучше ручной пул с контролем.
> 
> **Q:** Утечки видны только в `heap`?  
> **A:** Нет, `block` и `goroutine` профили тоже показывают зависания.
> 
> **Q:** Когда лучше ловить leak: в тестах или в staging?  
> **A:** В staging при длительной нагрузке — в юнит-тестах часто не видно.

---

## Полезные ссылки

- https://www.datadoghq.com/blog/go-memory-leaks/
    
- https://www.groundcover.com/blog/golang-pprof
    
- https://dev.to/gkampitakis/memory-leaks-in-go-3pcn
    
- https://medium.com/@caring_smitten_gerbil_914/hunting-memory-leaks-in-go-a-hands-on-guide-with-pprof-15a7f56ebcd9
    
- https://golang.org/pkg/runtime/pprof/
    
- https://github.com/google/pprof
